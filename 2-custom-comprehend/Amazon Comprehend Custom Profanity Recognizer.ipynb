{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING\n",
    "*The content in this notebook is, by design, hurtful, offensive, and hateful.*\n",
    "\n",
    "*The authors are grateful for the datasets made available by others to permit this kind of exploration, but are aware that some of this content is hurtful while other content may seem benign.  Some will find the association of dictionary words with these kinds of datasets separately hurtful.  The goal here is to offer a framework for exploration using AWS Services, not to opine on content.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "For moderation of user generated text content online, customers often ask about tools available to flag potentially offensive content.  While every community is ultimately responsible for its content standards, there are some general guidelines that community stewards tend to use to find the balance between protecting free speech online and guarding against speech that primarily insults, offends, or incites violence or hatred against individuals or groups of individuals.\n",
    "\n",
    "In practice, content moderation requires a lot more than identifying potentially offensive content; we share these links to remind you that this lab is not a substitute for a considerate content moderation program, but the techniques discussed here can be part of such a program.\n",
    "* [Content Moderation is Broken. Let Us Count the Ways](https://www.eff.org/deeplinks/2019/04/content-moderation-broken-let-us-count-ways), a provocative post by the Electronic Frontier Foundation\n",
    "* [The people policing the internet's most horrific content](https://www.bbc.com/news/business-49393858), a BBC News story on the working conditions for content moderators\n",
    "\n",
    "In research, profanity detection is considered distinct from hate speech and offensive language that may be directed toward individuals (or groups of individuals).  Take a look at the [SemEval-2019 tasks](http://alt.qcri.org/semeval2019/index.php?id=tasks) to get a sense of the language used to describe these efforts.\n",
    "\n",
    "For our lab today, we are going to focus on the narrow task of identifying profanity in tweets with a hope that participants learn how to use similar techniques to address specific needs.  Specifically, we're going to build an [Amazon Comprehend Custom Entity Recognizer](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html) to help us detect profanity in a curated collection of tweets.\n",
    "\n",
    "### Datasets\n",
    "* For a list of terms considered profane (our \"entity list\"), we used \"a list of 1,300+ English terms that could be found offensive\" made available by [Luis von Ahn's Research Group](https://www.cs.cmu.edu/~biglou/resources/).\n",
    "* For training and evaluation documents, we used a human-labeled tweet [dataset](https://github.com/t-davidson/hate-speech-and-offensive-language) shared by the authors of [Automated Hate Speech Detection and the Problem of Offensive Language](https://arxiv.org/pdf/1703.04009.pdf), an investigation into lexical detection methods for the separation of hate speech from other offensive language.\n",
    "  * ``count``:  number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "  * ``hate_speech``:  number of CF users who judged the tweet to be hate speech.\n",
    "  * ``offensive_language``:  number of CF users who judged the tweet to be offensive.\n",
    "  * ``neither``:  number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "  * ``class``:  class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS IAM Resources used in this notebook\n",
    "In general, this notebook does not use the AWS API to create or manipulate IAM resources; instructions are provided instead.\n",
    "\n",
    "The notebook code itself runs under a \"SageMaker execution role\" and has limited access, so participants will need to grant additional rights to be able to use Comprehend Custom.  In addition, Comprehend itself does not automatically have access to the Amazon S3 bucket used for data storage, so another IAM role (\"profanity-lab-role\") is used to grant access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's start off by getting to know our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "iamRole = get_execution_role()\n",
    "\n",
    "print('SageMaker execution role')\n",
    "print(iamRole) \n",
    "print('')\n",
    "print('This is the role that SageMaker would use to leverage AWS resources')\n",
    "print('(S3, CloudWatch) on your behalf.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create an Amazon S3 bucket where we can upload input/output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(service_name='s3', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name='profanity-lab-labbucket-1hrxlvhpl2gpf'\n",
    "\n",
    "# if the bucket hasn't already been created ...\n",
    "# s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just created a new bucket, you will need to grant the SageMaker instance execution role access to write to the new S3 bucket by attaching a policy similar to this one.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:HeadObject\",\n",
    "                \"s3:AbortMultipartUpload\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:s3:::profanity-lab-labbucket-1hrxlvhpl2gpf/private/labs/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's upload our training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='profanity-list.csv', \n",
    "    Bucket=bucket_name, \n",
    "    Key='private/labs/training/profanity-list.csv')\n",
    "s3.upload_file(\n",
    "    # Filename='profanity-training-docs.txt', \n",
    "    Filename='profanity-training-docs-1k.txt', \n",
    "    Bucket=bucket_name, \n",
    "    Key='private/labs/training/profanity-training-docs.txt')\n",
    "\n",
    "s3.list_objects(Bucket=bucket_name, Prefix='private/labs/training')['Contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now that our training data is in place, let's try to create a custom entity recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please ensure the execution role has the ability to call Comprehend\n",
    "comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the AWS Console, create an IAM Role so Comprehend has access to read input files and write output files.\n",
    "\n",
    "**profanity-lab-role**\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::profanity-lab-labbucket-1hrxlvhpl2gpf\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::profanity-lab-labbucket-1hrxlvhpl2gpf/private/labs/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"kms:CreateGrant\",\n",
    "                \"kms:Decrypt\",\n",
    "                \"kms:GenerateDatakey\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the ARN for the IAM role above (profanity-lab-role)\n",
    "comprehend_data_access_role_arn = 'arn:aws:iam::414696549938:role/profanity-lab-ComprehendLabRole-27L5L2J32HMR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the AWS Console, ensure that the notebook execution role can use this new role.  Add a policy statement similar to this one to the main policy for the execution role.\n",
    "\n",
    "*Remember to replace ``__AWS-ACCOUNT__`` with your AWS Account Id (12-digit).*\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Sid\": \"passrole1\",\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Action\": \"iam:PassRole\",\n",
    "    \"Resource\": \"arn:aws:iam::__AWS-ACCOUNT__:role/profanity-lab-role\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=comprehend.create_entity_recognizer(\n",
    "    RecognizerName='profanity',\n",
    "    DataAccessRoleArn=comprehend_data_access_role_arn,\n",
    "    InputDataConfig={\n",
    "        'EntityTypes': [ { \n",
    "            'Type': 'PROFANITY' }],\n",
    "        'EntityList': { \n",
    "            'S3Uri': 's3://' + bucket_name + '/private/labs/training/profanity-list.csv' },\n",
    "        'Documents': { \n",
    "            'S3Uri': 's3://' + bucket_name + '/private/labs/training/profanity-training-docs.txt' }\n",
    "    },\n",
    "    LanguageCode='en')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['EntityRecognizerArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the training job complete?  (It should take about 20 minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'])['EntityRecognizerProperties']['Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wait for it to finish..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = comprehend.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'])['EntityRecognizerProperties']['Status']\n",
    "while (status in ['SUBMITTED', 'TRAINING']):\n",
    "    status = comprehend.describe_entity_recognizer(\n",
    "        EntityRecognizerArn=result['EntityRecognizerArn'])['EntityRecognizerProperties']['Status']\n",
    "    print('.', end='')\n",
    "    time.sleep(60)\n",
    "\n",
    "print('')\n",
    "print(comprehend.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'])\n",
    "      ['EntityRecognizerProperties'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the training job fail (status is ``IN_ERROR``), please correct the issue, delete the recognizer, and try again.\n",
    "\n",
    "```\n",
    "comprehend.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'])['EntityRecognizerProperties']['Message']\n",
    "comprehend.delete_entity_recognizer(EntityRecognizerArn=result['EntityRecognizerArn'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?  Do we have a reasonable recognizer here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comprehend.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'])\n",
    "      ['EntityRecognizerProperties']['RecognizerMetadata']['EntityTypes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb, we would like an F1Score greater than 80 with precision and recall to match.  For more information on these metrics and how to improve accuracy, check out the [documentation](https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that we have an entity recognizer, let's try it out with a test dataset.\n",
    "\n",
    "First, let's upload our test data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('profanity-test-docs.txt', 'w+') as outfile:\n",
    "    with open('profanity-test-docs.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, quotechar='\"')\n",
    "        for row in reader:\n",
    "            if (row[-1] != 'tweet'):\n",
    "                outfile.write(row[-1].replace('\\n', ' ').replace('\"', ''))\n",
    "                outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l profanity-test-docs.*\n",
    "\n",
    "# line counts may not match up because the source file may have embedded newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='profanity-test-docs.txt', \n",
    "    Bucket=bucket_name, \n",
    "    Key='private/labs/test/profanity-test-docs.txt')\n",
    "s3.list_objects(Bucket=bucket_name, Prefix='private/labs/')['Contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start an entity recognition job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_result = comprehend.start_entities_detection_job(\n",
    "    JobName='profanity-2',\n",
    "    EntityRecognizerArn=result['EntityRecognizerArn'],\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/private/labs/test/profanity-test-docs.txt',\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE' },\n",
    "    OutputDataConfig={ 'S3Uri': 's3://' + bucket_name + '/private/labs/test/profanity-1/' },\n",
    "    DataAccessRoleArn=comprehend_data_access_role_arn,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "print(job_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wait for the job to finish.  This should take 7-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = comprehend.describe_entities_detection_job(\n",
    "    JobId=job_result['JobId'])['EntitiesDetectionJobProperties']['JobStatus']\n",
    "\n",
    "while (status == 'IN_PROGRESS'):\n",
    "    status = comprehend.describe_entities_detection_job(\n",
    "        JobId=job_result['JobId'])['EntitiesDetectionJobProperties']['JobStatus']\n",
    "    print('.', end='')\n",
    "    time.sleep(60)\n",
    "\n",
    "print('')\n",
    "print(comprehend.describe_entities_detection_job(JobId=job_result['JobId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the output so we can inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3URI = comprehend.describe_entities_detection_job(\n",
    "    JobId=job_result['JobId'])['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "p = urlparse(s3URI, allow_fragments=False)\n",
    "\n",
    "print('Downloading {}'.format(s3URI))\n",
    "s3.download_file(Bucket=p.netloc, Key=p.path.lstrip('/'), Filename='profanity_output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xvzf profanity_output.tar.gz && mv -v output profanity_output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 10 profanity_output.jsonl\n",
    "!tail -n 10 profanity-test-docs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep crap profanity-list.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "results_df = pd.read_json(path_or_buf='profanity_output.jsonl', lines=True)\n",
    "\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"profanity-test-docs.csv\", \n",
    "    quotechar='\"', quoting=csv.QUOTE_MINIMAL, escapechar='\\\\', engine='python', \n",
    "    warn_bad_lines=True)\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results_df = pd.merge(\n",
    "    left=test_df, right=results_df, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    #display(merged_results_df.drop(columns=['id', 'neither', 'File', 'Line']).head(25))\n",
    "    #display(merged_results_df[merged_results_df['tweet'].str.contains('stf')].drop(\n",
    "    #    columns=['id', 'neither', 'File', 'Line']).head(3))\n",
    "    display(merged_results_df[\n",
    "        (merged_results_df['class'] == 1) &\n",
    "        (merged_results_df['offensive_language'] > 2) & \n",
    "        (merged_results_df['Entities'].str.len() == 0)].drop(\n",
    "        columns=['id', 'neither', 'File', 'Line']).head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "As you can see from the examples above, our profanity detector works well with unambiguous examples, but could use more work with additional terms, acronyms, deliberate obfuscation, and contextual resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further explorations\n",
    "* Though entity lists offer an easy way to get started with custom entity recognizers, [https://docs.aws.amazon.com/comprehend/latest/dg/cer-annotation.html](annotations) do a better job of treating terms in context (e.g., \"gung ho\") and often yield better results.  With this in mind, it would be interesting to review the output from this first entity recognizer to create an annotated data set for a more sophisticated recognizer.\n",
    "* It might be extremely useful to build a [Custom Classifier](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) to detect hate speech.\n",
    "* To go deeper, consider [Sentia Labs' AWS SageMaker post](https://www.sentialabs.io/2019/01/30/SageMaker-In-Action.html) on text classification using the BlazingText algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
