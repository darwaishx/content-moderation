# Detecting unsafe content at scale using Amazon Comprehend

In this module you will learn how to use Amazon Comprehend to detect unsafe text at scale.

1. Open the SageMaker Notebook instance you created in previous module.

2. Click on the Open Jupyter button, and then from the Jupyter UI, click on folder `content-moderation` and then `2-custom-comprehend`.

3. Click on the Jupyter notebook `CustomComprehend` and follow the instructions in the notebook.

4. You will see unsafe text recognized in images and videos.

## Completion
You have successfully trained a custom Amazon Comprehend model to detect unsafe content. In the next module, [Comprehensive content moderation solution](../moderation-solution), you will learn how to combine different APIs from first two modules to build a content moderation solution.
