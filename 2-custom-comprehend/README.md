# Detecting unsafe content at scale using Amazon Comprehend

In this module you will learn how to use Amazon Comprehend to detect unsafe text at scale.

1. Open SageMaker instance you created in previous module.

2. From home screen, click on folder content-moderation and then 2-custom-comprehend.

3. Click on the Jupyter notebook CustomComprehend and follow instructions in the notebook.

4. You will see unsafe text recognized in images and videos.

## Completion
You have successfully trained custom Amazon Comprehend model to detect unsafe content. In the next module, [Comprehensive content moderation solution](../moderation-solution), you will learn how to combine different APIs from first two modules to build content moderation solution.
